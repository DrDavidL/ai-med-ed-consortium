# Generative AI Policy Guide for Medical Education

**A Composite Framework Synthesized from Leading Academic Health Systems**

*Compiled by the AI in Medical Education Consortium*

---

## Purpose

This guide synthesizes best practices from generative AI policies at Penn, Stanford, Yale, Vanderbilt, Miami, and UChicago to provide a comprehensive framework for institutions developing or refining their own AI governance. It balances educational innovation with patient safety, academic integrity, and the development of independent clinical reasoning skills.

---

## Core Principles

### 1. AI Augments, Not Replaces, Human Judgment
Generative AI tools are predictive models based on statistical patterns—not discovery engines. They may produce inaccuracies, fabricated references, or biased outputs. Human oversight, critical thinking, and accountability remain essential.

### 2. Transparency is Non-Negotiable
All AI use must be openly declared. This applies to students, faculty, and staff across coursework, clinical care, and scholarly work.

**Critical Clarification (UChicago Law):** Attribution does not permit use. Even with proper disclosure, certain uses remain prohibited—transparency alone does not make inappropriate use acceptable.

### 3. Privacy Protection is Paramount
Protected health information (PHI), personally identifiable information (PII), and sensitive institutional data must never be entered into non-approved AI tools—regardless of claims of compliance.

### 4. Accountability Rests with the User
Users bear full responsibility for all AI-generated content, including verification of accuracy, identification of bias, and compliance with applicable policies.

### 5. Context Determines Appropriate Use
AI policies vary by course, clinical site, and assignment. When specific guidance is absent, the default is: *permitted with full disclosure*.

---

## Quick Reference: Acceptable vs. Prohibited Uses

| Category | Acceptable (with approved tools) | Prohibited |
|----------|----------------------------------|------------|
| **Learning & Study** | Summarizing content, creating flashcards, generating practice questions, identifying knowledge gaps | Completing assignments/exams without permission, uploading exam items to public AI |
| **Clinical Care** | Evidence-based clinical decision support (with verification), EHR-embedded approved tools | Direct-to-chart documentation with non-approved tools, entering PHI into any non-approved tool |
| **Clinical Reasoning** | Searching guidelines (e.g., "What is the evidence for steroids in COPD?") | Generating initial differentials or management plans without faculty authorization |
| **Documentation** | Using explicitly course-approved EHR features | Copy-pasting AI-generated notes without clinician review, unauthorized AI scribes |
| **Scholarly Work** | Literature review assistance, formatting, drafting (with disclosure) | Uploading research data or unpublished work to non-approved tools |
| **Teaching** | Creating course materials, generating assessment items (with disclosure) | Non-disclosure of AI use in content creation or student evaluation |

---

## Defining Generative AI

*Adapted from UChicago Law School:*

**Generative AI** refers to tools that create original content (text, images, code) based on user prompts—such as ChatGPT, Claude, Copilot, or Gemini.

**Conventional tools** that are generally not subject to GenAI policies include:
- Search engines (Google, PubMed)
- Spell-check and basic grammar correction
- Citation managers
- Standard calculator functions

This distinction matters because policies targeting "AI use" should clearly specify whether they apply only to generative tools or to all AI-assisted features.

---

## Essential Policy Components

### 1. Data Protection Requirements

**Never enter into non-approved tools:**
- Protected health information (PHI)
- De-identified data that could be re-identified
- Student records (FERPA-protected)
- Research participant data
- Proprietary curricular materials or exam items
- High-risk institutional data
- Social Security numbers or payment card data

**Best Practice (Penn, Yale):** Align AI tool permissions with institutional data risk classification frameworks.

### 2. Disclosure and Citation Standards

When AI is used, disclosure must include:
- **Tool name** and model/version
- **Date** of use
- **Query prompt** submitted
- **Output excerpt** used (for substantial contributions)
- **How it was used** (brainstorming, drafting, editing, etc.)

**Key Point:** AI citation does not replace citations for primary and secondary sources.

### 3. Approved Tools Framework

Institutions should maintain a centrally managed registry of approved AI tools vetted for:
- HIPAA compliance
- FERPA compliance
- Contractual data protection guarantees
- Appropriate use-case authorization (e.g., clinical documentation vs. study aids)

**Examples of institutional registries:**
- Penn: PMACS AI Tools
- Stanford: Secure GPT, AI Playground

### 4. Clinical Skills Development

**Strongly discouraged** (unless explicitly authorized):
- Using AI for initial differential diagnosis generation
- Generating clinical assessments and management plans
- Replacing foundational clinical reasoning development

**Expressly prohibited:**
- AI-generated clinical notes in patient charts (except via approved EHR-embedded tools)
- Unauthorized use of AI medical scribes
- Bypassing clinical documentation requirements

**Rationale:** Students must develop independent clinical reasoning before integrating AI augmentation.

### 5. Academic Integrity

- AI use in examinations and assignments is prohibited unless explicitly permitted by instructors
- Students are responsible for inaccuracies in submitted work, regardless of source
- All outputs must be verified against trusted sources (guidelines, core texts, peer-reviewed literature)

**Exam Bright Line (UChicago Law):** Generative AI is absolutely prohibited during examinations—every word must be the student's own. However, studying with AI tools before exams is generally permitted unless otherwise specified.

**Detection Tool Limitations (Vanderbilt, Miami):**
- Traditional plagiarism checkers are unreliable for AI detection
- AI detection tools may show bias against non-native English speakers
- Use of such tools may raise FERPA concerns
- Detection scores alone are insufficient evidence for misconduct allegations

### 6. Faculty Responsibilities

Course directors and instructors must:
- Include AI use statements in syllabi with links to institutional policy
- Clearly communicate expectations verbally and in writing
- Specify which elements of assignments may use AI assistance
- Provide guidance on documentation, attribution, and validation
- Disclose when course materials or assessments were created with AI
- Disclose if AI detection software will be used

**Best Practice (Vanderbilt):** Have ongoing conversations with students throughout the semester, not just syllabus statements.

### 7. Multi-Site Considerations

Students rotating through multiple clinical sites must be aware that policies may vary:
- VA hospitals follow federal AI guidelines
- Children's hospitals may have separate institutional policies
- Non-affiliated sites require individual policy review

---

## Guiding Principles for Learners

*Adapted from University of Miami's Seven Principles:*

1. **AI aids thinking, not replacement of it** — Use AI to enhance understanding, not bypass learning
2. **All usage must be open and documented** — Transparency builds trust
3. **Engage responsibly with ethical considerations** — Consider bias, accuracy, and appropriateness
4. **Complete accountability for final products** — You own what you submit
5. **Follow instructor-specific guidelines** — Course rules supersede general policy
6. **Never enter confidential or personal data** — When in doubt, don't
7. **Recognize variation across contexts** — What's acceptable in one course may not be in another

---

## Red Flags for Potential Misuse

*From Vanderbilt's guidance for faculty:*

- Factual inaccuracies or errors inconsistent with course content
- Deviation from taught methodology without supporting citations
- Formulaic, emotionless tone lacking depth or personal reflection
- Inconsistency with student's prior work quality or voice
- Fake, broken, or unverifiable citations and URLs
- Sources unavailable through institutional library systems

---

## Reporting and Enforcement

- Suspected misuse, privacy concerns, or policy violations should be reported through established institutional channels
- Reports made in good faith should be protected from retaliation
- Violations may result in assignment/course failure or professionalism review
- Evidence for misconduct allegations should not rely solely on AI detection scores

---

## Sample Syllabus Language Options

Institutions may offer faculty a spectrum of options:

**Restrictive:** "Use of generative AI tools is not permitted for any assignments in this course unless explicitly authorized for a specific task."

**Conditional:** "AI tools may be used for brainstorming, outlining, and proofreading. AI may not be used to generate substantive content. All AI use must be disclosed."

**Open with Disclosure:** "Students may use AI tools to support their learning. All AI use must be documented, including the tool used and how it contributed to the work."

**Exploratory:** "This course encourages thoughtful experimentation with AI tools as part of developing AI literacy. Assignments will include reflection on AI's role in your work."

---

## Ongoing Review

Given the rapid evolution of generative AI capabilities, policies should be:
- Reviewed at minimum annually
- Updated as new tools and use cases emerge
- Communicated promptly to all stakeholders
- Informed by feedback from students, faculty, and clinical partners

---

## Source Policies

This guide synthesizes frameworks from:
- University of Pennsylvania Perelman School of Medicine
- Stanford University School of Medicine
- Yale University
- Vanderbilt University
- University of Miami
- University of Chicago

For institution-specific policies, refer to the original documents linked in the [AI in Medical Education Consortium Resources](../RESOURCES.md).

---

*This document is intended as a starting framework. Institutions should adapt these guidelines to their specific contexts, regulatory environments, and educational missions.*
