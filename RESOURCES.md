# AI in Medical Education Resources

A curated collection of educational materials, tools, and resources contributed by consortium member institutions and partners.

---

## Curricula & Learning Materials

### Using AI to Learn Medicine
A hands-on session exploring how AI can enhance medical learning and clinical reasoning through tools like SecureGPT, OpenEvidence, and NotebookLM. Targeted at first-year medical students.

- [Session Materials (PDF)](https://med.stanford.edu/content/dam/sm/ai-in-meded/documents/Using%20AI%20to%20Learn%20Medicine_September%202025.pdf)

*Source: Stanford University School of Medicine*

### Artificial Intelligence in Clinical Practice: A Curriculum for Medical Students
An evidence-informed modular curriculum providing foundational knowledge, clinical integration, ethical-legal frameworks, and critical evaluation of AI applications in healthcare.

- [Module List (PDF)](https://med.stanford.edu/content/dam/sm/ai-in-meded/documents/AI%20Curriculum--Module%20List.pdf)

*Source: Stanford University School of Medicine*

### Learning Digital Health & Data Science
A comprehensive collection of Jupyter notebooks and tools for learning data science with healthcare applications. Includes:

- **6-part foundational series**: From Python basics through neural networks and LLMs
- **Healthcare case studies**: Stroke analysis with AI/ML, synthetic data generation
- **Hands-on notebooks**: Pre-built Colab-ready notebooks for immediate use
- **AI-powered tools**: Case simulation, PubMed search optimization, automated analysis
- **Local development guides**: Setting up secure local LLM environments for sensitive data

Ideal for faculty development or as a starting point for learner-facing curricula.

- [GitHub Repository](https://github.com/DrDavidL/learning-dhds)

*Source: Northwestern University Feinberg School of Medicine*

### PSOM AI Curriculum Task Force Report
A comprehensive report from the PSOM AI Curriculum Task Force providing recommendations for integrating AI into undergraduate medical education. Key findings include:

- **Needs assessment**: 93% of faculty report limited AI knowledge; 33% of students have never encountered AI during rotations
- **Longitudinal curriculum framework**: AI competencies mapped across Core 1 (pre-clerkship), Core 2 (clerkship), and Core 3 (post-clerkship)
- **Six AI competencies** based on Russell et al. 2023: explaining AI, ethics/equity, AI-enhanced clinical encounters, evaluating AI tools, adapting to AI workflows, and professional development
- **Peer institution benchmarking**: Review of AI initiatives at 13 peer medical schools
- **Implementation roadmap**: Short-term, near-term, and long-term goals for curriculum integration

The report also includes detailed recommendations for faculty development and IT infrastructure to support AI education.

- [Full Report (PDF)](resources/penn/PSOM-AI-Curriculum-Report.pdf)

*Source: University of Pennsylvania Perelman School of Medicine*

---

## Frameworks & Methodologies

### AI-SPARC: Keeping the Human in the AI Loop
A five-step reflective cycle for educators using AI as a thought partner, ensuring human oversight throughout the process:

- **S – Self-Reflect**: Examine your teaching philosophy, core learning goals, and perspectives on AI before using AI tools
- **P – Prompt with a Model**: Use structured prompting methods like TRACI (Task, Role, Audience, Create, Intent) to ensure clarity
- **A – Academic Requirements**: Ground prompts in official standards such as ACGME milestones or specific competency statements
- **R – Research on Pedagogy**: Incorporate evidence-based educational theories (Miller's Pyramid, Kolb's Experiential Learning, Pangaro's RIME model)
- **C – Critique**: Critically evaluate AI outputs against your self-reflection, academic standards, and pedagogical research

The framework includes practical examples of using AI-SPARC iteratively to develop assessment items while maintaining educator oversight.

- [Full Article](https://learn.hms.harvard.edu/insights/all-insights/keeping-human-ai-loop-sparc)
- [TRACI Structured Prompting Guide](https://structuredprompt.com)
- [AAMC AI Tools for Educators Collection](https://www.aamc.org)

*Source: Harvard Medical School*

### DEFT-AI Framework: Integrating AI into Medical Education
A framework for incorporating reflection on AI usage in medical education, helping educators and learners critically evaluate their interactions with AI tools in clinical and educational contexts.

- [Full Article (NEJM)](https://www.nejm.org/doi/full/10.1056/NEJMra2503232)

*Source: Contributed via AI in Med Ed Consortium discussion*

---

## Policies & Governance

### Consortium Composite GenAI Policy Guide
A comprehensive framework synthesizing best practices from Penn, Stanford, Yale, Vanderbilt, Miami, UChicago, and Northwestern into a unified reference for institutions developing AI governance policies.

**Key Highlights:**
- **Quick Reference Table**: Acceptable vs. prohibited uses across learning, clinical care, documentation, and scholarly work
- **Five Core Principles**: AI augments (not replaces) judgment, transparency is non-negotiable, privacy is paramount, accountability rests with users, context determines appropriate use
- **"Attribution Does Not Permit Use"**: Disclosure alone doesn't make inappropriate use acceptable—a critical clarification from UChicago Law
- **Clinical Skills Guidance**: Clear distinction between clinical decision support (acceptable) and initial differential/management plan generation (discouraged without authorization)
- **Disclosure Standards**: What to include when citing AI use (tool, version, date, prompt, output, how used)
- **Detection Tool Limitations**: Why AI detection scores alone are insufficient for misconduct allegations
- **Sample Syllabus Language**: Four options from restrictive to exploratory for faculty adoption
- **Red Flags for Misuse**: Indicators faculty can use to identify potential unauthorized AI use

- [Full Guide (Markdown)](resources/Composite-GenAI-Policy-Guide.md)

*Source: AI in Medical Education Consortium synthesis of institutional policies*

---

### PSOM Undergraduate Medical Education GenAI Policy
A comprehensive policy establishing guidelines for acceptable use of generative AI in undergraduate medical education, addressing:

- **Permissions and approved tools**: HIPAA/FERPA-compliant tools vetted through Penn's registry
- **Accountability and disclosure**: Requirements for citing AI use and verifying outputs
- **Patient privacy protections**: Strict prohibitions on PHI in non-approved tools
- **Clinical skills development**: Guidelines distinguishing acceptable use (clinical decision support) from prohibited use (direct clinical documentation)
- **Coursework and examinations**: Clear boundaries for AI use in academic work
- **Instructor responsibilities**: Syllabus requirements and communication expectations

Includes a practical reference table categorizing acceptable vs. unacceptable uses across coursework, patient care, documentation, scholarly work, and faculty instruction.

- [Policy Document (PDF)](resources/penn/PSOM-GenAI-Policy-Draft.pdf)

*Source: University of Pennsylvania Perelman School of Medicine*

### Stanford MD/MSPA Generative AI Policy
Guidance for responsible use of generative AI in medical education, balancing innovation with professionalism, accuracy, and sensitive information protection.

- [Policy Document](https://med.stanford.edu/md/mdhandbook/section-3-md-requirements-procedures/3-32--generative-artificial-intelligence--ai--policy.html)

*Source: Stanford University School of Medicine*

### Vanderbilt Generative AI Resources
Guidance on maintaining academic integrity while using generative AI tools, including frameworks for appropriate use in educational settings.

- [Academic Integrity Guidelines](https://www.vanderbilt.edu/generative-ai/academic-integrity/)
- [Academic Affairs AI Guidance (PDF)](https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/439/2023/11/29200845/Academic-Affairs-Guidance-for-Artificial-Intelligence-Nov-29-2023.pdf)

*Source: Vanderbilt University*

### Teaching and Learning with AI
Resources and guidance for faculty on integrating AI into teaching and learning, including pedagogical strategies and policy considerations.

- [Teaching Guide](https://petal.miami.edu/teaching-guides-and-policies/teaching-and-learning-with-ai/index.html)

*Source: University of Miami*

### Yale Guidelines for Use of Generative AI Tools
Institutional guidelines from Yale's Provost office on the responsible use of generative AI tools in academic settings.

- [Guidelines](https://provost.yale.edu/news/guidelines-use-generative-ai-tools)

*Source: Yale University*

### University of Chicago Generative AI Resources
University-wide guidance on AI use, including data protection requirements, procurement pathways, and the PhoenixAI institutional platform. The Law School policy offers particularly useful frameworks for academic integrity.

**Notable from Law School Policy:**
- **Clear tool distinction**: Differentiates generative AI (creates original content) from conventional tools (search, spellcheck, grammar)
- **"Attribution does not permit use"**: Even with proper citation, certain uses remain prohibited—disclosure alone doesn't make inappropriate use acceptable
- **Exam bright line**: AI prohibited during exams, but studying with AI beforehand is permitted

- [University GenAI Guidance](https://genai.uchicago.edu/about/generative-ai-guidance)
- [Law School GenAI Policy](https://www.law.uchicago.edu/students/handbook/academicmatters/generative-ai)

*Source: University of Chicago*

### Northwestern University Generative AI Resources
University IT guidance with a data classification framework (Levels 1-4) for determining appropriate AI tool usage. The Feinberg School of Medicine policy provides clear guidelines aligned with LCME Element 3.5 (Learning Environment/Professionalism).

**Notable from Feinberg Policy:**
- **Process over product**: "The *process* of completing the work is as important as the final *product*, if not more so"—articulates why AI restrictions support learning
- **Curricular materials protection**: May only upload to Northwestern-authenticated systems (e.g., Copilot in Bing with NetID)
- **H&P/clinical notes**: Prohibited outside EHR-supported tools; grounds for clerkship failure

- [University IT GenAI Guidance](https://www.it.northwestern.edu/about/policies/guidance-on-the-use-of-generative-ai.html)
- [Feinberg Medical Student Policy (PDF)](https://www.feinberg.northwestern.edu/md-education/docs/policies/professionalism-learning-environment/use-of-generative-ai-tools-policy.pdf)

*Source: Northwestern University Feinberg School of Medicine*

---

## Video Resources

### AI in Medical Education Symposium (June 4, 2025)

| Session | Speaker(s) | Link |
|---------|-----------|------|
| Framing the Landscape | Jonathan Chen, MD, PhD | [Watch](https://youtu.be/JRc03UJR4TY) |
| LLMs & Prompt Engineering Workshop | Shivam Vedak, MD, MBA; Dong-han Yao, MD | [Watch](https://youtu.be/xlMon7sXGig) |
| Legal Liability in Medical AI | Michelle Mello, JD, PhD | [Watch](https://youtu.be/p8YYIQgzscM) |
| Lightning Demos (5 tools) | Multiple presenters | [Watch](https://youtu.be/R8B8k9NLtTc) |
| Panel Discussion | 7 faculty members | [Watch](https://youtu.be/20Q89ZAEVxU) |
| Closing Reflections | Jonathan Chen, MD, PhD | [Watch](https://youtu.be/VlLvUf3qBuM) |

*Source: Stanford University School of Medicine*

### Epic and Clinical Informatics Clerkship Practicum (January 2026)

| Session | Speaker | Link |
|---------|---------|------|
| Introduction to AI Logic | Barinaga Z | [Watch](https://bcove.video/4s6xfCZ) |
| AI Literacy for Clinical Training | Srikureja N | [Watch](https://bcove.video/48Tw6ay) |
| Practice-Based Learning and the Future of AI at Penn | Lai D | [Watch](https://bcove.video/4s6xfCZ) |

*Source: University of Pennsylvania Perelman School of Medicine*

---

## Partner Programs & Organizations

### Bridge2AI
An NIH Common Fund program creating flagship datasets and best practices for AI/ML in biomedical research. Their educational resources include:

- **AI/ML training modules**: Foundational courses on machine learning concepts for biomedical researchers
- **Data readiness guidance**: Standards and tools for preparing ethically-sourced, AI-ready datasets
- **Skills and workforce development**: Training the next generation of researchers in responsible AI

Bridge2AI emphasizes ethical AI development, data diversity, and interdisciplinary collaboration — principles directly aligned with medical education goals.

- [Bridge2AI Website](https://bridge2ai.org/)

*Source: NIH Common Fund / Bridge2AI Consortium*

### Stanford Partner Organizations

- [Stanford Human-Centered AI (HAI)](https://hai.stanford.edu/)
- [Stanford Center for AI in Medicine and Imaging (AIMI)](https://aimi.stanford.edu/)
- [Responsible AI for Safe and Equitable Health (RAISE)](https://raise.stanford.edu/)
- [Stanford Medicine Center for Biomedical Informatics Research (BMIR)](https://bmir.stanford.edu/)

*Source: Stanford University School of Medicine*

---

## Contributing Resources

We welcome resource contributions from all consortium members. To add resources:

1. Fork this repository
2. Add your resource to the appropriate section in this file
3. Include a clear description, link, and source attribution
4. Submit a Pull Request

All contributions should align with our [contribution guidelines](CONTRIBUTING.md).
